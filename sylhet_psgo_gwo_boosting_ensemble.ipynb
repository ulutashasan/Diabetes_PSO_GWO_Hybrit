{"cells":[{"cell_type":"code","execution_count":null,"id":"fbb02d05","metadata":{"id":"fbb02d05","outputId":"167836f9-2ce1-4217-8070-ade73b309e13"},"outputs":[],"source":["!pip install pyswarms"]},{"cell_type":"code","execution_count":null,"id":"191b7db3","metadata":{"id":"191b7db3"},"outputs":[],"source":["import numpy as np\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from time import time\n","from functools import partial\n","from functools import partial\n","import pyswarms as ps\n","from pyswarms.single.global_best import GlobalBestPSO\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":null,"id":"e3c6c41f","metadata":{"id":"e3c6c41f"},"outputs":[],"source":["# Load the dataset\n","data = pd.read_csv('../Sylhet.csv')"]},{"cell_type":"code","execution_count":null,"id":"e80f732b","metadata":{"id":"e80f732b","outputId":"1f0381a0-d220-428d-a88c-5f1778133e23"},"outputs":[],"source":["sutunlar=['Age', 'Gender', 'Polyuria', 'Polydipsia', 'sudden_weight_loss','weakness', 'Polyphagia', 'Genital_thrush', 'visual_blurring','Itching', 'Irritability', 'delayed_healing', 'partial_paresis','muscle_stiffness', 'Alopecia', 'Obesity', 'Class']\n","data.columns=sutunlar\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"4b1cc7df","metadata":{"id":"4b1cc7df","outputId":"b12d76ef-eaa6-400e-f7ea-6b4a88fa4d0e"},"outputs":[],"source":["from sklearn import preprocessing\n","labelencoder=preprocessing.LabelEncoder()\n","data.Gender=labelencoder.fit_transform(data['Gender'])\n","data.Polyuria=labelencoder.fit_transform(data['Polyuria'])\n","data.Polydipsia=labelencoder.fit_transform(data['Polydipsia'])\n","data.sudden_weight_loss=labelencoder.fit_transform(data['sudden_weight_loss'])\n","data.weakness=labelencoder.fit_transform(data['weakness'])\n","data.Polyphagia=labelencoder.fit_transform(data['Polyphagia'])\n","data.Genital_thrush=labelencoder.fit_transform(data['Genital_thrush'])\n","data.visual_blurring=labelencoder.fit_transform(data['visual_blurring'])\n","data.Itching=labelencoder.fit_transform(data['Itching'])\n","data.Irritability=labelencoder.fit_transform(data['Irritability'])\n","data.delayed_healing=labelencoder.fit_transform(data['delayed_healing'])\n","data.partial_paresis=labelencoder.fit_transform(data['partial_paresis'])\n","data.muscle_stiffness=labelencoder.fit_transform(data['muscle_stiffness'])\n","data.Alopecia=labelencoder.fit_transform(data['Alopecia'])\n","data.Obesity=labelencoder.fit_transform(data['Obesity'])\n","data.Class=labelencoder.fit_transform(data['Class'])\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"2409c131","metadata":{"id":"2409c131","outputId":"e855e72b-e293-4e56-c35e-b63915bbd0e0"},"outputs":[],"source":["data.shape #veri setinde kaç veri kaç sütun var gösterir."]},{"cell_type":"code","execution_count":null,"id":"000e2dc5","metadata":{"id":"000e2dc5","outputId":"4057fc54-a3b2-4d91-e669-b1947644caaf"},"outputs":[],"source":["print(data.groupby('Class').size()) #toplam çıktı sayılarını yazdırır."]},{"cell_type":"code","execution_count":null,"id":"34f0cac4","metadata":{"id":"34f0cac4"},"outputs":[],"source":["y = data['Class']\n","X = data.drop(['Class'],axis=1)"]},{"cell_type":"code","execution_count":null,"id":"a485e8f5","metadata":{"id":"a485e8f5"},"outputs":[],"source":["# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"c732fe0e","metadata":{"id":"c732fe0e"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,roc_curve,classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn import metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n","import numpy as np\n","import time\n","def evaluate_model(model, data_x, data_y):\n","    k_fold = KFold(5, shuffle=True, random_state=1)\n","\n","    predicted_targets = np.array([])\n","    actual_targets = np.array([])\n","\n","    TN = np.array([])\n","    TP = np.array([])\n","    FP = np.array([])\n","    FN = np.array([])\n","    F1_Score = np.array([])\n","    Recal_Score = np.array([])\n","\n","    Train_ACC =np.array([])\n","    Test_ACC = np.array([])\n","\n","    Precision_Score = np.array([])\n","    Train_Times = np.array([])\n","    Test_Times = np.array([])\n","\n","    AUCS = np.array([])\n","\n","    false_positive_rates = np.array([])\n","    true_positive_rates = np.array([])\n","    FPR1 = np.array([])\n","    FPR2 = np.array([])\n","    FPR3 = np.array([])\n","\n","    TPR1 = np.array([])\n","    TPR2 = np.array([])\n","    TPR3 = np.array([])\n","\n","    A_class_0_precision =  np.array([])\n","    A_class_0_recall =  np.array([])\n","    A_class_0_f1_score =  np.array([])\n","    A_class_0_support =  np.array([])\n","    A_class_1_precision =  np.array([])\n","    A_class_1_recall =  np.array([])\n","    A_class_1_f1_score =  np.array([])\n","    A_class_1_support =  np.array([])\n","    A_clf_report_acc = np.array([])\n","    A_class_macro_avg_precision =  np.array([])\n","    A_class_macro_avg_recall =  np.array([])\n","    A_class_macro_avg_f1_score =  np.array([])\n","    A_class_macro_avg_support =  np.array([])\n","    A_class_weighted_avg_precision =  np.array([])\n","    A_class_weighted_avg_recall =  np.array([])\n","    A_class_weighted_avg_f1_score =  np.array([])\n","    A_class_weighted_avg_support =  np.array([])\n","    train_x = []\n","    train_y = []\n","    test_x = []\n","    test_y = []\n","    for train_ix, test_ix in k_fold.split(data_x):\n","        train_x, train_y, test_x, test_y = data_x.iloc[train_ix], data_y.iloc[train_ix], data_x.iloc[test_ix], data_y.iloc[test_ix]\n","\n","        # Fit the classifier\n","        t0 = time.time()\n","        classifier = model.fit(train_x, train_y)\n","        train_time = time.time() - t0\n","\n","        # Predict the labels of the test set samples\n","        t0 = time.time()\n","        predicted_labels = classifier.predict(test_x)\n","        test_time = time.time() - t0\n","        predicted_targets = np.append(predicted_targets, predicted_labels)\n","        actual_targets = np.append(actual_targets, test_y)\n","\n","        target_names = ['class_0','class_1']\n","        clf_rept = classification_report(predicted_labels, test_y, output_dict=True)\n","\n","\n","        class_0_precision =  clf_rept['0']['precision']\n","        class_0_recall =  clf_rept['0']['recall']\n","        class_0_f1_score =  clf_rept['0']['f1-score']\n","        class_0_support =  clf_rept['0']['support']\n","\n","        class_1_precision =  clf_rept['1']['precision']\n","        class_1_recall =  clf_rept['1']['recall']\n","        class_1_f1_score =  clf_rept['1']['f1-score']\n","        class_1_support =  clf_rept['1']['support']\n","\n","        clf_report_acc = clf_rept['accuracy']\n","\n","        class_macro_avg_precision =  clf_rept['macro avg']['precision']\n","        class_macro_avg_recall =  clf_rept['macro avg']['recall']\n","        class_macro_avg_f1_score =  clf_rept['macro avg']['f1-score']\n","        class_macro_avg_support =  clf_rept['macro avg']['support']\n","\n","        class_weighted_avg_precision =  clf_rept['weighted avg']['precision']\n","        class_weighted_avg_recall =  clf_rept['weighted avg']['recall']\n","        class_weighted_avg_f1_score =  clf_rept['weighted avg']['f1-score']\n","        class_weighted_avg_support =  clf_rept['weighted avg']['support']\n","\n","        #add to\n","\n","        A_class_0_precision = np.append(A_class_0_precision,class_0_precision)\n","        A_class_0_recall = np.append(A_class_0_recall,class_0_recall)\n","        A_class_0_f1_score = np.append(A_class_0_f1_score,class_0_f1_score)\n","        A_class_0_support = np.append(A_class_0_support,class_0_support)\n","\n","        A_class_1_precision = np.append(A_class_1_precision,class_1_precision)\n","        A_class_1_recall = np.append(A_class_1_recall,class_1_recall)\n","        A_class_1_f1_score = np.append(A_class_1_f1_score,class_1_f1_score)\n","        A_class_1_support = np.append(A_class_1_support,class_1_support)\n","\n","        A_clf_report_acc = np.append(A_clf_report_acc,clf_report_acc)\n","\n","        A_class_macro_avg_precision = np.append(A_class_macro_avg_precision,class_macro_avg_precision)\n","        A_class_macro_avg_recall = np.append(A_class_macro_avg_recall,class_macro_avg_recall)\n","        A_class_macro_avg_f1_score = np.append(A_class_macro_avg_f1_score,class_macro_avg_f1_score)\n","        A_class_macro_avg_support = np.append(A_class_macro_avg_support,class_macro_avg_support)\n","        A_class_weighted_avg_precision = np.append(A_class_weighted_avg_precision,class_weighted_avg_precision)\n","        A_class_weighted_avg_recall = np.append(A_class_weighted_avg_recall,class_weighted_avg_recall)\n","        A_class_weighted_avg_f1_score = np.append(A_class_weighted_avg_f1_score,class_weighted_avg_f1_score)\n","        A_class_weighted_avg_support = np.append(A_class_weighted_avg_support,class_weighted_avg_support)\n","        tn, fp, fn, tp = confusion_matrix(predicted_labels, test_y).ravel()\n","\n","        f1 = f1_score(test_y, predicted_labels,average='micro')\n","\n","        recall = recall_score(test_y, predicted_labels)\n","\n","        test_Acc = accuracy_score(test_y, predicted_labels)\n","        precisionScore = precision_score(test_y, predicted_labels)\n","        #train acc\n","        trainPred = classifier.predict(train_x)\n","        train_acc = accuracy_score(trainPred, train_y)\n","\n","        auc = metrics.roc_auc_score(test_y, predicted_labels)\n","\n","\n","        false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(test_y, predicted_labels)\n","\n","\n","        print('false_positive_rate len: ',len(false_positive_rate))\n","        print(\"k fold true_positive_rate:\", true_positive_rate)\n","        print(\"k fold false_positive_rate:\", false_positive_rate)\n","\n","        fpr1 = false_positive_rate[0]\n","\n","\n","        fpr2 = false_positive_rate[1]\n","        try:\n","          fpr3 = false_positive_rate[2]\n","          FPR3 = np.append(FPR3,fpr3)\n","        except Exception as e:\n","          print(e)\n","\n","        tpr1 = true_positive_rate[0]\n","        tpr2 = true_positive_rate[1]\n","        try:\n","          tpr3 = true_positive_rate[2]\n","          TPR3 = np.append(TPR3,tpr3)\n","        except Exception as e:\n","          print(e)\n","\n","\n","        FPR1 = np.append(FPR1,fpr1)\n","        FPR2 = np.append(FPR2,fpr2)\n","\n","\n","        TPR1 = np.append(TPR1,tpr1)\n","        TPR2 = np.append(TPR2,tpr2)\n","\n","\n","\n","        #print(\"false_positive_rate: \",false_positive_rate)\n","        #print(\"len\", len(false_positive_rate))\n","        #print(\"true_positive_rate: \" , true_positive_rate)\n","\n","\n","\n","\n","       #add to df\n","\n","        Train_Times = np.append(Train_Times,train_time)\n","        Test_Times = np.append(Test_Times,test_time)\n","        F1_Score = np.append(F1_Score, f1)\n","        Recal_Score = np.append(Recal_Score,recall)\n","        Train_ACC = np.append(Train_ACC,train_acc)\n","        Test_ACC = np.append(Test_ACC,test_Acc)\n","        Precision_Score = np.append(Precision_Score,precisionScore)\n","        TN = np.append(TN, tn)\n","        TP = np.append(TP, tp)\n","        FN = np.append(FN, fn)\n","        FP = np.append(FP, fp)\n","        AUCS = np.append(AUCS,auc)\n","        false_positive_rates = np.append(false_positive_rates,false_positive_rate)\n","        true_positive_rates = np.append(true_positive_rates,true_positive_rate)\n","\n","    TP = (np.mean(TP))\n","    TN = (np.mean(TN))\n","    FP = (np.mean(FP))\n","    FN = (np.mean(FN))\n","    print('test: ',Test_ACC)\n","    print('F1_Score: ',F1_Score)\n","    print('Recal_Score: ',Recal_Score)\n","    print('Train_ACC: ',Train_ACC)\n","    print('Precision_Score: ',Precision_Score)\n","    F1_Score = (np.mean(F1_Score))\n","    Recal_Score = (np.mean(Recal_Score))\n","    Train_ACC = (np.mean(Train_ACC))\n","\n","    Test_ACC = (np.mean(Test_ACC))\n","    Precision_Score = np.mean(Precision_Score)\n","    Train_Times = np.mean(Train_Times)\n","    Test_Times = np.mean(Test_Times)\n","\n","    AUCS = np.mean(AUCS)\n","    FPR1 = np.mean(FPR1)\n","    FPR2 = np.mean(FPR2)\n","\n","    TPR1 = np.mean(TPR1)\n","    TPR2 = np.mean(TPR2)\n","\n","    A_class_0_precision =  np.mean(A_class_0_precision)\n","    A_class_0_recall =  np.mean(A_class_0_recall)\n","    A_class_0_f1_score =  np.mean(A_class_0_f1_score)\n","    A_class_0_support =  np.mean(A_class_0_support)\n","    A_class_1_precision =  np.mean(A_class_1_precision)\n","    A_class_1_recall =  np.mean(A_class_1_recall)\n","    A_class_1_f1_score =  np.mean(A_class_1_f1_score)\n","    A_class_1_support =  np.mean(A_class_1_support)\n","    A_clf_report_acc = np.mean(A_clf_report_acc)\n","    A_class_macro_avg_precision =  np.mean(A_class_macro_avg_precision)\n","    A_class_macro_avg_recall =  np.mean(A_class_macro_avg_recall)\n","    A_class_macro_avg_f1_score =  np.mean(A_class_macro_avg_f1_score)\n","    A_class_macro_avg_support =  np.mean(A_class_macro_avg_support)\n","    A_class_weighted_avg_precision =  np.mean(A_class_weighted_avg_precision)\n","    A_class_weighted_avg_recall =  np.mean(A_class_weighted_avg_recall)\n","    A_class_weighted_avg_f1_score =  np.mean(A_class_weighted_avg_f1_score)\n","    A_class_weighted_avg_support =  np.mean(A_class_weighted_avg_support)\n","\n","    try:\n","\n","      TPR3 = np.mean(TPR3)\n","      FPR3 = np.mean(FPR3)\n","      false_positive_rates = np.array([FPR1,FPR2,FPR3])\n","      true_positive_rates = np.array([TPR1,TPR2,TPR3])\n","\n","    except:\n","      print(1)\n","      false_positive_rates = np.array([FPR1,FPR2])\n","      true_positive_rates = np.array([TPR1,TPR2])\n","\n","    return TN, TP, FN, FP, F1_Score, Recal_Score, Train_ACC, Test_ACC, Precision_Score, Train_Times, Test_Times, AUCS, false_positive_rates, true_positive_rates,A_class_0_precision,A_class_0_recall ,A_class_0_f1_score,A_class_0_support ,A_class_1_precision,A_class_1_recall ,A_class_1_f1_score,A_class_1_support,A_clf_report_acc ,A_class_macro_avg_precision,A_class_macro_avg_recall,A_class_macro_avg_f1_score,A_class_macro_avg_support,A_class_weighted_avg_precision,A_class_weighted_avg_recall,A_class_weighted_avg_f1_score,A_class_weighted_avg_support\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"a93beba7","metadata":{"id":"a93beba7"},"outputs":[],"source":["xgb = XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","                 colsample_bynode=None, colsample_bytree=0.8947165815903877,\n","\n","                 learning_rate=0.5409745594945771,\n","                 max_depth=12.434434460765205,n_estimators=235.99816565991492,\n","\n","                 reg_alpha=1.702903502267796,\n","                 reg_lambda=1.4966619576498557,\n","                 subsample=0.7724145511648155, )"]},{"cell_type":"code","execution_count":null,"id":"4acba336","metadata":{"id":"4acba336","outputId":"3c998c9b-5e6f-4d9b-c4fe-05702392e9ad"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","\n","ensemble_boosting_models = []\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","from sklearn.model_selection import cross_val_score\n","\n","import seaborn as sns\n","sns.set()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","ada_boost = AdaBoostClassifier(base_estimator=xgb, n_estimators=50, random_state=42)\n","TN, TP, FN, FP, F1_Score, Recal_Score, Train_ACC, Test_ACC, Precision_Score, Train_Times, Test_Times, AUCS, false_positive_rates, true_positive_rates,A_class_0_precision,A_class_0_recall ,A_class_0_f1_score,A_class_0_support ,A_class_1_precision,A_class_1_recall ,A_class_1_f1_score,A_class_1_support,A_clf_report_acc ,A_class_macro_avg_precision,A_class_macro_avg_recall,A_class_macro_avg_f1_score,A_class_macro_avg_support,A_class_weighted_avg_precision,A_class_weighted_avg_recall,A_class_weighted_avg_f1_score,A_class_weighted_avg_support  = evaluate_model(ada_boost,X, y)\n","\n","print(\"mean f1: \",F1_Score)\n","print(\"mean Recal_Score: \",Recal_Score)\n","print(\"mean Train_ACC: \",Train_ACC)\n","print(\"mean Test_ACC: \",Test_ACC)\n","print(\"mean Precision_Score: \",Precision_Score)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"408c7e64","metadata":{"id":"408c7e64"},"outputs":[],"source":["def get_bounds(search_space_values):\n","    lb = np.array([min(values) for values in search_space_values])\n","    ub = np.array([max(values) for values in search_space_values])\n","    return lb, ub"]},{"cell_type":"code","execution_count":null,"id":"d4ef7864","metadata":{"id":"d4ef7864"},"outputs":[],"source":["class GreyWolfOptimizer:\n","\n","    def __init__(self, func, lb, ub, dim, n_wolves=20, n_generations=100):\n","        self.func = func\n","        self.lb = lb\n","        self.ub = ub\n","        self.dim = dim\n","        self.n_wolves = n_wolves\n","        self.n_generations = n_generations\n","\n","    def optimize(self, *args, **kwargs):\n","        # Initialize alpha, beta, and delta positions and scores\n","        alpha_pos = np.zeros(self.dim)\n","        beta_pos = np.zeros(self.dim)\n","        delta_pos = np.zeros(self.dim)\n","        alpha_score = float(\"inf\")\n","        beta_score = float(\"inf\")\n","        delta_score = float(\"inf\")\n","\n","        # Initialize wolf positions\n","        positions = self.initialize_positions()\n","\n","        for t in range(self.n_generations):\n","            for i in range(self.n_wolves):\n","                # Calculate the fitness score\n","                fitness = self.func(positions[i], *args, **kwargs)\n","\n","                if fitness < alpha_score:\n","                    alpha_score = fitness\n","                    alpha_pos = np.copy(positions[i])\n","                elif fitness < beta_score:\n","                    beta_score = fitness\n","                    beta_pos = np.copy(positions[i])\n","                elif fitness < delta_score:\n","                    delta_score = fitness\n","                    delta_pos = np.copy(positions[i])\n","\n","            a = 2 - t * (2 / self.n_generations)\n","\n","            for i in range(self.n_wolves):\n","                positions[i] = self.update_position(positions[i], alpha_pos, beta_pos, delta_pos, a)\n","\n","        return alpha_pos, alpha_score\n","\n","    def initialize_positions(self):\n","        positions = np.zeros((self.n_wolves, self.dim))\n","        for i in range(self.dim):\n","            positions[:, i] = np.random.uniform(self.lb[i], self.ub[i], self.n_wolves)\n","        return positions\n","\n","    def update_position(self, position, alpha_pos, beta_pos, delta_pos, a):\n","        A1 = 2 * a * np.random.rand() - a\n","        A2 = 2 * a * np.random.rand() - a\n","        A3 = 2 * a * np.random.rand() - a\n","\n","        C1 = 2 * np.random.rand()\n","        C2 = 2 * np.random.rand()\n","        C3 = 2 * np.random.rand()\n","\n","        D_alpha = abs(C1 * alpha_pos - position)\n","        D_beta = abs(C2 * beta_pos - position)\n","        D_delta = abs(C3 * delta_pos - position)\n","\n","        X1 = alpha_pos - A1 * D_alpha\n","        X2 = beta_pos - A2 * D_beta\n","        X3 = delta_pos - A3 * D_delta\n","\n","        new_position = (X1 + X2 + X3) / 3\n","        new_position = np.clip(new_position, self.lb, self.ub)\n","\n","        return new_position"]},{"cell_type":"code","execution_count":null,"id":"9a31e0ed","metadata":{"id":"9a31e0ed"},"outputs":[],"source":["# Define objective function for PSO-GWO hybrid model\n","def pso_gwo_hybrid(clf, X, y, pso_options, gwo_options, search_space, ridge_solver_options=None):\n","    search_space_keys = list(search_space.keys())\n","    search_space_values = [search_space[key] for key in search_space_keys]\n","    lb, ub = get_bounds(search_space_values)\n","\n","    def objective_function(params_array, clf, X, y, search_space_keys, ridge_solver_options=None):\n","        if len(params_array.shape) == 1:\n","            params_array = params_array.reshape(1, -1)\n","\n","        param_dict = {}\n","        for i, key in enumerate(search_space_keys):\n","            if key == \"solver\" and ridge_solver_options is not None:\n","                param_dict[key] = ridge_solver_options[int(params_array[0][i])]\n","            elif key in [\"n_estimators\", \"max_iter\", \"max_depth\"]:\n","                param_dict[key] = int(params_array[0][i])\n","            else:\n","                param_dict[key] = float(params_array[0][i])\n","\n","        clf.set_params(**param_dict)\n","        scores = cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error')\n","        return -np.mean(scores)\n","\n","    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=len(search_space_keys), options=pso_options, bounds=(lb, ub))\n","    cost_pso, pos_pso = optimizer.optimize(lambda x: objective_function(x.reshape(1, -1), clf, X, y, search_space_keys, ridge_solver_options), iters=100)\n","    print(\"PSO Best Cost and Position:\", cost_pso, pos_pso)\n","\n","    gwo = GreyWolfOptimizer(objective_function, lb, ub, len(search_space_keys), n_wolves=20, n_generations=100)\n","    alpha_pos_gwo, alpha_score_gwo = gwo.optimize(clf, X, y, search_space_keys=search_space_keys, ridge_solver_options=ridge_solver_options)\n","\n","    print(\"GWO Best Cost and Position:\", alpha_score_gwo, alpha_pos_gwo)\n","\n","    if cost_pso < alpha_score_gwo:\n","        best_cost, best_pos = cost_pso, pos_pso\n","    else:\n","        best_cost, best_pos = alpha_score_gwo, alpha_pos_gwo\n","\n","    # Translate the best position back to the original parameter values\n","    best_params = {}\n","    for i, key in enumerate(search_space_keys):\n","        if key == 'solver' and ridge_solver_options:\n","            best_params[key] = ridge_solver_options[int(best_pos[i])]\n","        else:\n","            best_params[key] = float(best_pos[i])\n","\n","    return best_params\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"1c4fe4ee","metadata":{"id":"1c4fe4ee"},"outputs":[],"source":["# Define PSO options\n","pso_options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}"]},{"cell_type":"code","execution_count":null,"id":"2ec29722","metadata":{"id":"2ec29722"},"outputs":[],"source":["# Define GWO options\n","gwo_options = {'n_particles': 40, 'n_iterations': 100}"]},{"cell_type":"code","execution_count":null,"id":"cd8e7061","metadata":{"id":"cd8e7061"},"outputs":[],"source":["import pickle\n","X,y = pickle.load(open(\"train_test.p\",\"rb\"))"]},{"cell_type":"code","execution_count":null,"id":"7fd5c4a0","metadata":{"id":"7fd5c4a0"},"outputs":[],"source":["# Define base models and their hyperparameter search space\n","ridge_search_space = {\n","    'alpha': (0.001, 100),\n","    'max_iter': (1, 10000),\n","    'tol': (1e-6, 1e-3),\n","}\n","search_space = ridge_search_space.copy()\n","lasso = Lasso(random_state=42)\n","lasso_search_space = {\n","    'alpha': (0.001, 100),\n","    'max_iter': (1, 10000),\n","    'tol': (1e-6, 1e-3),\n","}\n","\n","ridge_solver_options = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n","ridge_solver_indices = list(range(len(ridge_solver_options)))\n","\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","import lightgbm as lgb\n","from sklearn.neural_network import MLPClassifier\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","\n","\n","\n","base_models = [\n","    ('decisionTree',DecisionTreeClassifier(),{\n","         'ccp_alpha':[10,1,0.1, 0.01, 0.001,0.0001,0.00001],\n","         'max_depth': np.arange(1,50,1),\n","\n","     }),\n","\n","    ('gausNB',GaussianNB(),{\n","\n","         'var_smoothing': np.logspace(0,-10, num=50000)\n","     }),\n","\n","\n","    ('svc',SVC(kernel= 'linear'),{\n","\n","         'C': np.logspace(-3,3,1000),\n","        'gamma':np.arange(1,10,1)\n","     }),\n","\n","    ('logisticRegression',LogisticRegression(),{\n","         'C': np.logspace(-3,3,1000)\n","     }),\n","\n","\n","    ('gbm', GradientBoostingClassifier(random_state=42),\n","     {\n","         'n_estimators': [10, 50, 100, 200],\n","         'learning_rate': [1e-2, 1e-1, 1],\n","         'max_depth': [3, 5, 7]\n","     }),\n","\n","    ('mlp',MLPClassifier(solver= 'lbfgs'),\n","     {\n","        'alpha': 10.0 ** -np.arange(1, 10),\n","        'max_iter':np.arange(1,1500,10),\n","\n","\n","    }),\n","\n","\n","    ('lgbm',lgb.LGBMClassifier(),{'colsample_bytree':np.arange(0.1,1.0,0.1),\n","                                  'max_depth': np.arange(1,50,5),\n","                                  'min_split_gain':np.arange(0.1,1.0,0.1),\n","                                  'n_estimators':np.arange(80,200,10),\n","                                  'reg_alpha':np.arange(1.0,2.0,0.1),\n","                                  'reg_lambda':[1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9 ],\n","                                  'subsample':[0.3, 0.4,0.5,0.6,0.7, 0.8, 0.9],\n","\n","                                 }),\n","    ('etc', ExtraTreesClassifier(criterion='gini',random_state=42),\n","     {\n","         'n_estimators':np.arange(1,150,10),\n","         'max_depth': np.arange(1,10000,50)\n","     }),\n","\n","    ('random_forest', RandomForestClassifier(random_state=42),\n","     {\n","         'n_estimators': [10, 50, 100, 200],\n","         'max_depth': [10000, 10, 30, 50]\n","     }),\n","\n","\n","    ('xgb', XGBClassifier(),\n","     {\n","         'learning_rate': [1e-2, 1e-1, 1],\n","        'colsample_bytree':np.arange(1e-1,1,1e-1),\n","         'max_depth': np.arange(5,50,5),\n","         'n_estimators':np.arange(100,1001,100),\n","         'reg_alpha':np.arange(1.1,2.9,0.1),\n","         'reg_lambda':np.arange(1.1,2.9,0.1),\n","         'subsample':np.arange(0.1,1.0,0.1)\n","     }),\n","\n","]\n"]},{"cell_type":"code","execution_count":null,"id":"8755ff12","metadata":{"id":"8755ff12","outputId":"ce145bb7-59c3-4fa2-9ba5-8246937f1373","scrolled":true},"outputs":[],"source":["# Perform hyperparameter tuning\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","tuned_models = []\n","\n","for name, model, search_space in base_models:\n","    print(name)\n","    if isinstance(model, Ridge):\n","        search_space['solver'] = ridge_solver_indices\n","        best_params = pso_gwo_hybrid(\n","            model, X, y, pso_options, gwo_options, search_space, ridge_solver_options=ridge_solver_options\n","        )\n","    else:\n","        best_params = pso_gwo_hybrid(model, X, y, pso_options, gwo_options, search_space)\n","\n","    model.set_params(**best_params)\n","    tuned_models.append((name, model))\n"]},{"cell_type":"code","execution_count":null,"id":"8b582519","metadata":{"id":"8b582519"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2cb86428","metadata":{"id":"2cb86428"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6abe2675","metadata":{"id":"6abe2675"},"outputs":[],"source":["tuned_models = pickle.load(open(\"tuned_models.p\",\"rb\"))"]},{"cell_type":"code","execution_count":null,"id":"d9af5f3e","metadata":{"id":"d9af5f3e","outputId":"a794e4e5-832a-48c4-9267-7396efd5fa79"},"outputs":[],"source":["tuned_models"]},{"cell_type":"code","execution_count":null,"id":"473bfd35","metadata":{"id":"473bfd35"},"outputs":[],"source":["\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","import lightgbm as lgb\n","from sklearn.neural_network import MLPClassifier\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","\n","models = []"]},{"cell_type":"code","execution_count":null,"id":"e980f650","metadata":{"id":"e980f650"},"outputs":[],"source":["models = []\n","models.append(('decisionTree', DecisionTreeClassifier(ccp_alpha=1e-05, max_depth=7.095070009310916)))\n","\n","models.append(('gausNB', GaussianNB(var_smoothing=1e-10)))\n","\n","models.append(('svc', SVC(C=3.5935257455272436, gamma=1.549970109349049, kernel='linear')))\n","models.append(('logisticRegression', LogisticRegression(C=231.34818551397362)))\n","\n","models.append(('gbm',\n","   GradientBoostingClassifier(learning_rate=0.6139225781915966,\n","                              max_depth=3.986376806922101,\n","                              n_estimators=69.54443282161446, random_state=42)))\n","\n","models.append(('mlp',MLPClassifier(alpha=0.09360867552213359, max_iter=1491.0, solver='lbfgs')))\n","\n","models.append(('lgbm',  lgb.LGBMClassifier(colsample_bytree=0.8163918277196188,\n","                  max_depth=15.821035341131518, min_split_gain=0.1472549856113242,\n","                  n_estimators=87.92453274677831, reg_alpha=1.0835851529291876,\n","                  reg_lambda=1.2037398089039828, subsample=0.387064086940639)))\n","\n","models.append(('etc',\n","   ExtraTreesClassifier(max_depth=2455.3509963029087,\n","                        n_estimators=47.866155187233744, random_state=42)))\n","models.append(('random_forest',\n","   RandomForestClassifier(max_depth=9530.503377228759,\n","                          n_estimators=22.075592248366302, random_state=42)))\n","\n","models.append(('xgb',\n","   XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","                 colsample_bynode=None, colsample_bytree=0.8947165815903877,\n","                 enable_categorical=False, gamma=None, gpu_id=None,\n","                 importance_type=None, interaction_constraints=None,\n","                 learning_rate=0.5409745594945771, max_delta_step=None,\n","                 max_depth=12.434434460765205, min_child_weight=None,\n","                 monotone_constraints=None, n_estimators=235.99816565991492,\n","                 n_jobs=None, num_parallel_tree=None, predictor=None,\n","                 random_state=None, reg_alpha=1.702903502267796,\n","                 reg_lambda=1.4966619576498557, scale_pos_weight=None,\n","                 subsample=0.7724145511648155, tree_method=None,\n","                 validate_parameters=None, verbosity=None)))"]},{"cell_type":"code","execution_count":null,"id":"818a4b37","metadata":{"id":"818a4b37","outputId":"2da239a0-2926-4925-a0b4-82da73f2014f"},"outputs":[],"source":["# Train the Ensemble ADa Boosting Regression model,\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_boosting_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","        print(model)\n","        ada_boost = AdaBoostClassifier(base_estimator=model, n_estimators=50, random_state=42)\n","        ada_boost.fit(X_train, y_train)\n","        ensemble_boosting_models.append((name, ada_boost))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"efd62ce4","metadata":{"id":"efd62ce4"},"outputs":[],"source":["!pip install openpyxl"]},{"cell_type":"code","execution_count":null,"id":"b68b85f7","metadata":{"id":"b68b85f7","scrolled":true},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score,confusion_matrix\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","\n","import seaborn as sns\n","sns.set()\n","\n","results = []\n","\n","for name, model in ensemble_boosting_models:\n","\n","    y_pred = model.predict(X_test)\n","\n","    score = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test,y_pred ,average='macro')\n","    f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","    f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","\n","    fit_time = time()\n","    mean_fit_time = fit_time / len(X_train)\n","    test_time = time()\n","\n","    results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_ada_bosting_results2.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"4dff1131","metadata":{"id":"4dff1131","outputId":"4daafda8-4254-458d-e140-49aa76a424b8","scrolled":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","rocs = []\n","import seaborn as sn\n","for name, model in ensemble_boosting_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title('Boosting ensemble with '+ name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([\"Boosting Ensemble \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"24781433","metadata":{"id":"24781433","outputId":"06f20e90-7f85-4ae9-a651-1803d912c68a"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"cfec0c90","metadata":{"id":"cfec0c90","outputId":"04e636f4-614f-4760-9367-a4ced331eb61"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"5484404b","metadata":{"id":"5484404b","outputId":"fe7af9c4-5a24-48f6-aa5e-d58c7b7314d2"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(20, 20))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=12)\n","    ax.set_ylabel(metric, fontsize=12)\n","    ax.set_title(f'Model {metric}', fontsize=14)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_ada_boosting_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0809a25b","metadata":{"id":"0809a25b","outputId":"c9eafd60-3bf5-4253-b3ab-d49f551c7a87","scrolled":true},"outputs":[],"source":["# Train the  Bagging Ensemble\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_bagging_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","        print(model)\n","        bagging_ensemble = BaggingClassifier(base_estimator=model, n_estimators=50, random_state=42)\n","        bagging_ensemble.fit(X_train, y_train)\n","        ensemble_bagging_models.append((name, bagging_ensemble))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"c7c388dc","metadata":{"id":"c7c388dc"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in ensemble_bagging_models:\n","\n","    y_pred = model.predict(X_test)\n","\n","    score = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test,y_pred ,average='macro')\n","    f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","    f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","\n","    fit_time = time()\n","    mean_fit_time = fit_time / len(X_train)\n","    test_time = time()\n","    results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_bagging_results.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"4fb4db50","metadata":{"id":"4fb4db50","outputId":"bdf57cc9-1b0c-493e-980b-94803afbe66a"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"dced1dfa","metadata":{"id":"dced1dfa","outputId":"cac70b5f-ac62-497a-c067-a1d3081c7483"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","\n","import seaborn as sn\n","rocs = []\n","for name, model in ensemble_bagging_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title('Bagging ensemble with '+ name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([\"Bagging Ensemble \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])"]},{"cell_type":"code","execution_count":null,"id":"75469625","metadata":{"id":"75469625","outputId":"af96858c-e8f6-452c-9dbb-40c8e5a5e0f0"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"9b2ae89d","metadata":{"id":"9b2ae89d","outputId":"433fa90a-508a-46db-db24-c3ae3785a976"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(40, 40))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_bagging_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"2bb37a32","metadata":{"id":"2bb37a32","outputId":"9a5d8315-9c0b-4b89-bc6a-2482493d4b00"},"outputs":[],"source":["# Train the  Super Learner model,\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from mlens.ensemble import SuperLearner\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_superLearner_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","\n","        print(model)\n","        try:\n","            superlearner = SuperLearner()\n","            superlearner.add(model)\n","\n","            superlearner.fit(X_train, y_train)\n","            ensemble_superLearner_models.append((name, superlearner))\n","        except:\n","            print('hata')\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"b0917794","metadata":{"id":"b0917794"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in ensemble_superLearner_models:\n","\n","    y_pred = model.predict(X_test)\n","\n","    score = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test,y_pred ,average='macro')\n","    f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","    f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","\n","    fit_time = time()\n","    mean_fit_time = fit_time / len(X_train)\n","    test_time = time()\n","    results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_superLearner_results.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"6e92c87b","metadata":{"id":"6e92c87b","outputId":"c14066d1-8596-4ef8-e516-516b4484e08b"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"8556e9a8","metadata":{"id":"8556e9a8","outputId":"e848c49b-fadd-454d-ab81-35d4a11075aa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","rocs = []\n","import seaborn as sn\n","for name, model in ensemble_superLearner_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title('Super Learner ensemble with '+ name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([\"Super Learner Ensemble \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])\n"]},{"cell_type":"code","execution_count":null,"id":"d7607dc3","metadata":{"id":"d7607dc3","outputId":"0418eb85-69b5-4e57-b776-bf2cb52b6bbe"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"58d22eec","metadata":{"id":"58d22eec","outputId":"237c2466-226c-46c9-f7c1-4f458d82c640"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(40, 40))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_super_learner_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"feeb8a9e","metadata":{"id":"feeb8a9e","outputId":"9cf6b794-2e7c-4da0-dd0d-49b99118feee","scrolled":true},"outputs":[],"source":["\n","# Train the  Stacking Ensemble Boosting Regression model,\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import StackingClassifier\n","\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_stacking_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","\n","        print(model)\n","        level0 = list()\n","        level0.append((str(model), model))\n","        stacking_ensemble = StackingClassifier(estimators=level0)\n","        stacking_ensemble.fit(X_train, y_train)\n","        ensemble_stacking_models.append((name, stacking_ensemble))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"da4c445c","metadata":{"id":"da4c445c"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in ensemble_stacking_models:\n","\n","    y_pred = model.predict(X_test)\n","\n","    score = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test,y_pred ,average='macro')\n","    f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","    f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","\n","    fit_time = time()\n","    mean_fit_time = fit_time / len(X_train)\n","    test_time = time()\n","    results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_stacking_ensemble_results.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"3d202727","metadata":{"id":"3d202727","outputId":"8c0f2193-489f-429f-d923-87d8b94ca8c5"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"d3b71bc9","metadata":{"id":"d3b71bc9","outputId":"4af58626-46f6-43a7-8ea3-2ba68e1a28f0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","rocs = []\n","import seaborn as sn\n","for name, model in ensemble_stacking_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title('Stacking ensemble with '+ name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([\"Stacking Ensemble \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])\n"]},{"cell_type":"code","execution_count":null,"id":"cded187a","metadata":{"id":"cded187a","outputId":"be6c9c52-7707-4809-a5f9-f36a4e4bb654"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8388c0b1","metadata":{"id":"8388c0b1","outputId":"a158eb4f-4a11-48fa-88a5-a051686bad91"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(40, 40))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_Stacking_Ensemble_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"5d56ddee","metadata":{"id":"5d56ddee","outputId":"21784932-46e6-474f-81f5-8a813b315092","scrolled":true},"outputs":[],"source":["\n","# Train the  Max Voting Ensemble Boosting Regression model,\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import VotingClassifier\n","\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_maxVoting_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","        print(model)\n","        level0 = list()\n","        level0.append((str(model), model))\n","        max_voting = VotingClassifier(estimators=[(str(name),model)], voting='hard')\n","\n","        max_voting.fit(X_train, y_train)\n","        ensemble_maxVoting_models.append((name, max_voting))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"5b9583ed","metadata":{"id":"5b9583ed"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in ensemble_maxVoting_models:\n","\n","    y_pred = model.predict(X_test)\n","\n","    score = accuracy_score(y_test, y_pred)\n","    f1_macro = f1_score(y_test,y_pred ,average='macro')\n","    f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","    f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","    recall = recall_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","\n","    fit_time = time()\n","    mean_fit_time = fit_time / len(X_train)\n","    test_time = time()\n","    results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_max_voting_results.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"e5c8b152","metadata":{"id":"e5c8b152","outputId":"15aa8b75-ef51-4544-a24c-eae25fcfdd51"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"a246faef","metadata":{"id":"a246faef","outputId":"7c926d2d-77da-49f0-fdfb-0ab3e31e069d"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","rocs = []\n","import seaborn as sn\n","for name, model in ensemble_maxVoting_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title('Max Voting  with '+ name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([\"Max Voting \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])\n"]},{"cell_type":"code","execution_count":null,"id":"59e94609","metadata":{"id":"59e94609","outputId":"5be6b91e-331c-4524-e616-b8915270618d"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"1a1eee4e","metadata":{"id":"1a1eee4e","outputId":"0081086c-2a2a-4362-ae01-4704f792d938"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(50, 50))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_max_voting_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ca2e5984","metadata":{"id":"ca2e5984","outputId":"885f119f-1ad4-4a48-dfa7-e3831c061643","scrolled":true},"outputs":[],"source":["\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import VotingClassifier\n","\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","ensemble_soft_voting_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","\n","        print(model)\n","        level0 = list()\n","        level0.append((str(model), model))\n","        max_voting = VotingClassifier(estimators=[(str(name),model)], voting='soft')\n","\n","        max_voting.fit(X_train, y_train)\n","        ensemble_soft_voting_models.append((name, max_voting))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"4ca3bff7","metadata":{"id":"4ca3bff7","outputId":"d9471ac0-f6bd-4919-b194-45fab8b9d05b"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","\n","import seaborn as sn\n","rocs = []\n","for name, model in ensemble_soft_voting_models:\n","    try:\n","        y_pred = model.predict(X_test)\n","\n","        confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","        cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","        cm_display.plot(cmap=plt.cm.YlGnBu,)\n","        plt.title('Average Voting with '+ name)\n","        plt.show()\n","        from sklearn.metrics import classification_report\n","        print(classification_report(y_test, y_pred))\n","        auc = metrics.roc_auc_score(y_test, y_pred)\n","        false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","        rocs.append([\"Average Voting \"+ \" \" + name ,auc,false_positive_rate,true_positive_rate])\n","    except:\n","            print(1)"]},{"cell_type":"code","execution_count":null,"id":"01b3de8a","metadata":{"id":"01b3de8a","outputId":"e3da6ec7-3571-48b0-f1ca-bf6c338b8630"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in ensemble_soft_voting_models:\n","    try:\n","        y_pred = model.predict(X_test)\n","\n","        score = accuracy_score(y_test, y_pred)\n","        f1_macro = f1_score(y_test,y_pred ,average='macro')\n","        f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","        f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","        recall = recall_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred)\n","\n","        fit_time = time()\n","        mean_fit_time = fit_time / len(X_train)\n","        test_time = time()\n","        results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","    except Exception as e:\n","        print(e)\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('model_average_soft_voting_results.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"229db571","metadata":{"id":"229db571","outputId":"9a76bf79-bc73-4ed6-8eb2-e060ae4e75b7"},"outputs":[],"source":["plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"110ab391","metadata":{"id":"110ab391","outputId":"23f28e40-8527-4ed5-bb5c-0738ed0b5057"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"38e55252","metadata":{"id":"38e55252","outputId":"241697ff-4e46-4a85-f40a-9cadf90faee5"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(40, 40))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"model_soft_voting_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"54e001c5","metadata":{"id":"54e001c5","outputId":"ea5613e3-5eae-4439-e9c6-db0c660386ad","scrolled":true},"outputs":[],"source":["\n","# Train the Soft Model\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from sklearn.ensemble import VotingClassifier\n","\n","cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","soft_models = []\n","\n","for name, model in models:\n","    try:\n","        if isinstance(model, ExtraTreesClassifier):\n","            model.set_params(n_estimators=int(model.get_params()['n_estimators']),\n","                            max_depth = int(model.get_params()['max_depth'])\n","                            )\n","        if isinstance(model, RandomForestClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']))\n","\n","        if isinstance(model, GradientBoostingClassifier):\n","            model.set_params(max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             learning_rate=(model.get_params()['learning_rate']))\n","\n","\n","\n","        if isinstance(model, lgb.LGBMClassifier):\n","            model.set_params(colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             min_split_gain=(model.get_params()['min_split_gain']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","        if isinstance(model, XGBClassifier):\n","            model.set_params(learning_rate=(model.get_params()['learning_rate']),\n","                             colsample_bytree=(model.get_params()['colsample_bytree']),\n","                             max_depth=int(model.get_params()['max_depth']),\n","                             n_estimators=int(model.get_params()['n_estimators']),\n","                             reg_alpha=(model.get_params()['reg_alpha']),\n","                             reg_lambda=(model.get_params()['reg_lambda']),\n","                             subsample=(model.get_params()['subsample'])\n","                            )\n","\n","        if isinstance(model, DecisionTreeClassifier):\n","            model.set_params(ccp_alpha=(model.get_params()['ccp_alpha']),\n","                             max_depth=int(model.get_params()['max_depth'])\n","                            )\n","\n","        if isinstance(model, GaussianNB):\n","            model.set_params(var_smoothing=(model.get_params()['var_smoothing'])\n","                            )\n","\n","        if isinstance(model, SVC):\n","            model.set_params(C=(model.get_params()['C']),\n","                             gamma=(model.get_params()['gamma'])\n","                            )\n","\n","        if isinstance(model, LogisticRegression):\n","            model.set_params(C=(model.get_params()['C'])\n","                            )\n","\n","        if isinstance(model, MLPClassifier):\n","            model.set_params(alpha=(model.get_params()['alpha']),\n","                             max_iter=(model.get_params()['max_iter'])\n","                            )\n","\n","\n","\n","        print(model)\n","\n","\n","        model.fit(X_train, y_train)\n","        soft_models.append((name, model))\n","    except Exception as e:\n","        print('hata /n',e)"]},{"cell_type":"code","execution_count":null,"id":"2075844c","metadata":{"id":"2075844c"},"outputs":[],"source":["# Save the results to an Excel file\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score,recall_score,precision_score\n","results = []\n","\n","for name, model in soft_models:\n","    try:\n","        y_pred = model.predict(X_test)\n","\n","        score = accuracy_score(y_test, y_pred)\n","        f1_macro = f1_score(y_test,y_pred ,average='macro')\n","        f1_mikro = f1_score(y_test,y_pred ,average='micro')\n","        f1_weighted = f1_score(y_test,y_pred ,average='weighted')\n","        recall = recall_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred)\n","\n","        fit_time = time()\n","        mean_fit_time = fit_time / len(X_train)\n","        test_time = time()\n","        results.append([name, score, f1_macro, f1_mikro,f1_weighted,recall, precision,fit_time, mean_fit_time, test_time])\n","    except:\n","        print(1)\n","results_df = pd.DataFrame(results, columns=['Model','Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision','Fit Time', 'Mean Fit Time', 'Test Time'])\n","results_df.to_excel('soft_models.xlsx', index=False)"]},{"cell_type":"code","execution_count":null,"id":"17dcd7d9","metadata":{"id":"17dcd7d9","outputId":"1ab0770f-2c7c-49c5-d764-6de396e1325f"},"outputs":[],"source":["results_df"]},{"cell_type":"code","execution_count":null,"id":"24614211","metadata":{"id":"24614211","outputId":"bffc8333-9af8-40d8-d04b-8bcdc0641b48"},"outputs":[],"source":["# Plot the results\n","fig, axs = plt.subplots(3,3, figsize=(40, 40))\n","metrics = ['Accuarcy score', 'f1-score-macro', 'f1-score-micro', 'f1-score-weighted','recall','precision', 'Fit Time', 'Mean Fit Time', 'Test Time']\n","model_names = results_df['Model'].tolist()\n","\n","for i, ax in enumerate(axs.flat):\n","    metric = metrics[i]\n","    metric_values = results_df[metric].tolist()\n","    ax.bar(model_names, metric_values)\n","    ax.set_xlabel('Models', fontsize=18)\n","    ax.set_ylabel(metric, fontsize=18)\n","    ax.set_title(f'Model {metric}', fontsize=20)\n","    ax.tick_params(axis='both', which='major', labelsize=10)\n","\n","plt.tight_layout()\n","plt.savefig(\"soft_models_metrics.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"20a4bb95","metadata":{"id":"20a4bb95","outputId":"dce63ae2-facd-4573-b78d-b89b07257317"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy\n","from sklearn import metrics\n","rocs = []\n","import seaborn as sn\n","for name, model in soft_models:\n","    y_pred = model.predict(X_test)\n","\n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n","\n","    cm_display.plot(cmap=plt.cm.YlGnBu,)\n","    plt.title(name)\n","    plt.show()\n","    from sklearn.metrics import classification_report\n","    print(classification_report(y_test, y_pred))\n","    auc = metrics.roc_auc_score(y_test, y_pred)\n","    false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n","    rocs.append([ name ,auc,false_positive_rate,true_positive_rate])\n"]},{"cell_type":"code","execution_count":null,"id":"12659247","metadata":{"id":"12659247","outputId":"144cf41b-c767-4f4c-d41a-d3942969ff05"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","plt.figure(figsize=(25, 15))\n","plt.title('ROC')\n","for i in range(len(rocs)):\n","    plt.plot(rocs[i][2], rocs[i][3], label= rocs[i][0]+'=%0.2f' %rocs[i][1])\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1], 'r--')\n","plt.xlim([0,1])\n","plt.ylim([0,1])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f6e7c25b","metadata":{"id":"f6e7c25b"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":5}
